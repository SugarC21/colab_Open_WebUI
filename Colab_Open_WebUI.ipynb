{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SugarC21/colab_Open_WebUI/blob/main/Colab_Open_WebUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCWqBVjnO6yq"
      },
      "source": [
        "# **Open WebUI + Ollama in Colab**\n",
        "\n",
        "This notebook sets up **Open WebUI** (Python 3.11) and **Ollama** on Google Colab. Both can optionally be installed in Google Drive to persist across sessions. **ngrok** is used to provide a public URL for the Open WebUI interface (port 8081). Ollama runs locally on port 11422.\n",
        "\n",
        "### **Features**\n",
        "1. **Install** Open WebUI in a Python 3.11 virtual environment.\n",
        "2. **Optionally** persist Open WebUI and Ollama in Google Drive.\n",
        "3. **Expose** Open WebUI via ngrok.\n",
        "4. **Hide** Ollama from the public URL (internal only).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup_form"
      },
      "source": [
        "#@title **Setup**\n",
        "use_gdrive = True #@param {type:\"boolean\"}\n",
        "use_ngrok_auth = False #@param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "\n",
        "BASE_PATH = \"/content\"\n",
        "if use_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_PATH = \"/content/drive/MyDrive/Open-WebUI\"\n",
        "    os.makedirs(BASE_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Using base path:\", BASE_PATH)\n",
        "print(\"Using ngrok auth token:\", use_ngrok_auth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI2ThRxgO6yt"
      },
      "source": [
        "## (Optional) Using Authentication Token\n",
        "If you want a stable subdomain or advanced ngrok features, toggle `use_ngrok_auth` and store your token in an environment variable named `ngrok_auth_token` (e.g. `%env ngrok_auth_token=YOUR_TOKEN`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pb6LmGnO6yu"
      },
      "source": [
        "## Install Dependencies\n",
        "Installs Python 3.11, venv, development packages, and system tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_deps"
      },
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y python3.11 python3.11-venv python3.11-dev pciutils lshw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gmrhd59O6yu"
      },
      "source": [
        "## Install Ollama\n",
        "If `use_gdrive` is true, Ollama will be stored in Drive; otherwise, it's installed system-wide (ephemeral)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_ollama"
      },
      "source": [
        "if use_gdrive:\n",
        "    print(\"Persisting Ollama to Drive...\")\n",
        "    import os\n",
        "    ollama_dir = os.path.join(BASE_PATH, 'ollama')\n",
        "    ollama_bin = os.path.join(ollama_dir, 'ollama')\n",
        "\n",
        "    if os.path.exists(ollama_bin):\n",
        "        print(\"Ollama already exists in Drive.\")\n",
        "    else:\n",
        "        print(\"Downloading Ollama (Linux x86_64) to Drive...\")\n",
        "        os.makedirs(ollama_dir, exist_ok=True)\n",
        "        OLLAMA_VERSION = \"v0.0.16\"  # example pinned version\n",
        "        DOWNLOAD_URL = f\"https://github.com/jmorganca/ollama/releases/download/{OLLAMA_VERSION}/ollama-{OLLAMA_VERSION}-Linux-x86_64.tar.gz\"\n",
        "        !wget -q \"$DOWNLOAD_URL\" -O /tmp/ollama.tar.gz\n",
        "        !tar -xzf /tmp/ollama.tar.gz -C \"$ollama_dir\" --strip-components 1\n",
        "        !chmod +x \"$ollama_bin\"\n",
        "        print(\"Ollama persisted at:\", ollama_bin)\n",
        "else:\n",
        "    print(\"Installing Ollama system-wide (ephemeral)\")\n",
        "    !curl -fsSL https://ollama.com/install.sh | sh\n",
        "    print(\"Ollama installed for this session.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omC2IodDO6yv"
      },
      "source": [
        "## Set Up Virtual Environment & Install Open WebUI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "open_webui_install"
      },
      "source": [
        "import os\n",
        "\n",
        "venv_path = os.path.join(BASE_PATH, \"venv\")\n",
        "if not os.path.exists(venv_path):\n",
        "    print(\"Creating Python 3.11 virtual environment...\")\n",
        "    !python3.11 -m venv \"$venv_path\"\n",
        "\n",
        "print(\"Upgrading pip...\")\n",
        "!\"$venv_path/bin/python\" -m pip install --upgrade pip\n",
        "\n",
        "print(\"Installing Open WebUI...\")\n",
        "!\"$venv_path/bin/pip\" install open-webui\n",
        "\n",
        "print(\"Open WebUI installation complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gfSyBDnO6yv"
      },
      "source": [
        "## Create a Script to Start Both Servers\n",
        "Ollama runs on port **11422**. Open WebUI runs on port **8081**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "start_servers"
      },
      "source": [
        "server_script_path = os.path.join(BASE_PATH, 'start_servers.py')\n",
        "\n",
        "if use_gdrive:\n",
        "    ollama_bin = os.path.join(BASE_PATH, 'ollama', 'ollama')\n",
        "else:\n",
        "    ollama_bin = 'ollama'\n",
        "\n",
        "script_content = f'''\\\n",
        "import subprocess, threading, time\n",
        "\n",
        "OLLAMA_CMD = \"{ollama_bin}\"\n",
        "\n",
        "def start_ollama():\n",
        "    subprocess.run([OLLAMA_CMD, 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "def start_open_webui():\n",
        "    subprocess.run(['./venv/bin/open-webui', 'serve', '--port', '8081'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "threading.Thread(target=start_ollama).start()\n",
        "time.sleep(5)\n",
        "threading.Thread(target=start_open_webui).start()\n",
        "'''\n",
        "\n",
        "with open(server_script_path, 'w') as f:\n",
        "    f.write(script_content)\n",
        "\n",
        "print(\"Created:\", server_script_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWaWvyTXO6yw"
      },
      "source": [
        "## Start Servers & Expose Open WebUI via ngrok\n",
        "After a short wait, the Open WebUI tunnel link will be displayed. Ollama remains hidden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_ngrok"
      },
      "source": [
        "!pip install pyngrok --quiet\n",
        "\n",
        "import time, os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "if use_ngrok_auth:\n",
        "    token = os.environ.get('ngrok_auth_token', '')\n",
        "    if token:\n",
        "        ngrok.set_auth_token(token)\n",
        "        print(\"ngrok auth token set.\")\n",
        "    else:\n",
        "        print(\"No 'ngrok_auth_token' found. Proceeding without auth token.\")\n",
        "\n",
        "print(\"Starting servers...\")\n",
        "!\"$venv_path/bin/python\" \"$server_script_path\" &\n",
        "time.sleep(20)\n",
        "\n",
        "webui_tunnel = ngrok.connect(8081, \"http\")\n",
        "print(\"Open WebUI URL:\", webui_tunnel.public_url)\n",
        "\n",
        "# Hidden tunnel for Ollama (no print)\n",
        "ollama_tunnel = ngrok.connect(11422, \"http\")\n",
        "\n",
        "print(\"\\nSetup complete. Use the URL above for Open WebUI.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}