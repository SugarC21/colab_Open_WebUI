{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SugarC21/colab_Open_WebUI/blob/main/Colab_Open_WebUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAyXm571VpYH"
      },
      "source": [
        "# **Open WebUI + Ollama in Colab**\n",
        "\n",
        "This notebook sets up **Open WebUI** (Python 3.11) and **Ollama** on Google Colab. Both can optionally be installed in Google Drive to persist across sessions. **ngrok** is used to provide a public URL for Open WebUI (port 8081). Ollama runs in the background on port 11422.\n",
        "\n",
        "### **Features**\n",
        "1. **Install** Open WebUI in a Python 3.11 virtual environment.\n",
        "2. **Optionally** persist both Open WebUI and Ollama in Google Drive.\n",
        "3. **Expose** Open WebUI via ngrok.\n",
        "4. **Hide** Ollama from the public URL (internal only).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup_form"
      },
      "source": [
        "#@title **Setup**\n",
        "use_gdrive = True #@param {type:\"boolean\"}\n",
        "use_ngrok_auth = False #@param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "\n",
        "# If Google Drive is enabled, mount and set BASE_PATH to persist.\n",
        "BASE_PATH = \"/content\"\n",
        "if use_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_PATH = \"/content/drive/MyDrive/Open-WebUI\"\n",
        "    os.makedirs(BASE_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Using base path:\", BASE_PATH)\n",
        "print(\"Using ngrok auth token:\", use_ngrok_auth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWHh98dsVpYK"
      },
      "source": [
        "## (Optional) Using Authentication Token\n",
        "1. Toggle `use_ngrok_auth` above.\n",
        "2. Provide your token as `ngrok_auth_token` through either Colab secrets or an environment variable.\n",
        "   - **Colab secrets** example:\n",
        "     ```python\n",
        "     from google.colab import userdata\n",
        "     token = userdata.get('ngrok_auth_token')\n",
        "     ```\n",
        "   - **Environment variable** example:\n",
        "     ```bash\n",
        "     %env ngrok_auth_token=YOUR_TOKEN\n",
        "     ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDpUdEeKVpYK"
      },
      "source": [
        "## Install Dependencies\n",
        "Installs Python 3.11, venv, dev packages, and system tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_deps"
      },
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y python3.11 python3.11-venv python3.11-dev pciutils lshw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhQE3aP7VpYL"
      },
      "source": [
        "## Install Ollama\n",
        "We always use the **official script**:\n",
        "```\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "```\n",
        "\n",
        "- If `use_gdrive` is **True**, we **copy** the installed Ollama binary into Drive for persistence.\n",
        "- Otherwise, Ollama remains ephemeral."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_ollama"
      },
      "source": [
        "ollama_drive_path = os.path.join(BASE_PATH, 'ollama')\n",
        "ollama_bin_drive = os.path.join(ollama_drive_path, 'ollama')\n",
        "\n",
        "if use_gdrive:\n",
        "    # If we have a persisted binary, skip reinstallation\n",
        "    if os.path.exists(ollama_bin_drive):\n",
        "        print(\"Ollama binary already present in Drive.\")\n",
        "        print(\"(To reinstall/update, remove or overwrite the existing file in Drive.)\")\n",
        "    else:\n",
        "        print(\"Installing Ollama system-wide (one time)...\")\n",
        "        !curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "        # Attempt to locate the installed Ollama binary (should be /usr/local/bin/ollama)\n",
        "        import subprocess\n",
        "        which_ollama = subprocess.check_output(['which', 'ollama']).decode('utf-8').strip()\n",
        "\n",
        "        print(f\"Copying Ollama from {which_ollama} to Drive...\")\n",
        "        os.makedirs(ollama_drive_path, exist_ok=True)\n",
        "        !cp \"$which_ollama\" \"$ollama_bin_drive\"\n",
        "        !chmod +x \"$ollama_bin_drive\"\n",
        "        print(\"Ollama persisted in Drive at:\", ollama_bin_drive)\n",
        "else:\n",
        "    print(\"Installing Ollama system-wide (ephemeral)\")\n",
        "    !curl -fsSL https://ollama.com/install.sh | sh\n",
        "    print(\"Ollama installed for this session.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4teDhgr6VpYL"
      },
      "source": [
        "## Set Up Virtual Environment & Install Open WebUI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "open_webui_install"
      },
      "source": [
        "import os\n",
        "\n",
        "venv_path = os.path.join(BASE_PATH, \"venv\")\n",
        "if not os.path.exists(venv_path):\n",
        "    print(\"Creating Python 3.11 virtual environment...\")\n",
        "    !python3.11 -m venv \"$venv_path\"\n",
        "\n",
        "print(\"Upgrading pip...\")\n",
        "!\"$venv_path/bin/python\" -m pip install --upgrade pip\n",
        "\n",
        "print(\"Installing Open WebUI...\")\n",
        "!\"$venv_path/bin/pip\" install open-webui\n",
        "\n",
        "print(\"Open WebUI installation complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dThbR4JZVpYM"
      },
      "source": [
        "## Create a Script to Start Both Servers\n",
        "Ollama runs on **port 11422**. Open WebUI runs on **port 8081**.\n",
        "\n",
        "If using Drive, we run Ollama from the Drive copy. Otherwise, we run the system-wide install."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "start_servers"
      },
      "source": [
        "import os\n",
        "\n",
        "server_script_path = os.path.join(BASE_PATH, 'start_servers.py')\n",
        "\n",
        "if use_gdrive:\n",
        "    ollama_bin = ollama_bin_drive  # Use the persisted copy\n",
        "else:\n",
        "    ollama_bin = 'ollama'          # Use system-wide ephemeral\n",
        "\n",
        "script_content = f'''\\\n",
        "import subprocess, threading, time\\n\\n\n",
        "OLLAMA_CMD = \"{ollama_bin}\"\\n\\n\n",
        "def start_ollama():\\n\n",
        "    subprocess.run([OLLAMA_CMD, 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\\n\\n\n",
        "def start_open_webui():\\n\n",
        "    subprocess.run(['./venv/bin/open-webui', 'serve', '--port', '8081'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\\n\\n\n",
        "threading.Thread(target=start_ollama).start()\\n\n",
        "time.sleep(5)\\n\n",
        "threading.Thread(target=start_open_webui).start()\\n\n",
        "'''\n",
        "\n",
        "with open(server_script_path, 'w') as f:\n",
        "    f.write(script_content)\n",
        "\n",
        "print(\"Created:\", server_script_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nGlk9mdVpYN"
      },
      "source": [
        "## Start Servers & Expose Open WebUI via ngrok\n",
        "Open WebUI is on **port 8081**, Ollama on **port 11422** (not publicly exposed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_ngrok"
      },
      "source": [
        "!pip install pyngrok --quiet\n",
        "\n",
        "import time, os\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "def get_ngrok_token():\n",
        "    # 1) Check Colab secrets\n",
        "    secret_token = userdata.get('ngrok_auth_token')\n",
        "    if secret_token:\n",
        "        return secret_token\n",
        "    # 2) Check environment variable\n",
        "    env_token = os.environ.get('ngrok_auth_token', '')\n",
        "    if env_token:\n",
        "        return env_token\n",
        "    return ''\n",
        "\n",
        "if use_ngrok_auth:\n",
        "    token = get_ngrok_token()\n",
        "    if token:\n",
        "        ngrok.set_auth_token(token)\n",
        "        print(\"ngrok auth token set.\")\n",
        "    else:\n",
        "        print(\"No 'ngrok_auth_token' found. Proceeding without auth token.\")\n",
        "\n",
        "print(\"Starting servers...\")\n",
        "venv_path = os.path.join(BASE_PATH, 'venv')\n",
        "server_script_path = os.path.join(BASE_PATH, 'start_servers.py')\n",
        "!\"$venv_path/bin/python\" \"$server_script_path\" &\n",
        "time.sleep(20)\n",
        "\n",
        "webui_tunnel = ngrok.connect(8081, \"http\")\n",
        "print(\"Open WebUI URL:\", webui_tunnel.public_url)\n",
        "\n",
        "# Hidden tunnel for Ollama\n",
        "ollama_tunnel = ngrok.connect(11422, \"http\")\n",
        "\n",
        "print(\"\\nSetup complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}