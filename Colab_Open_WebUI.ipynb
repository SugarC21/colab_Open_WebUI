{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SugarC21/colab_Open_WebUI/blob/main/Colab_Open_WebUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOel4mEDQBfn"
      },
      "source": [
        "# **Open WebUI + Ollama in Colab**\n",
        "\n",
        "This notebook sets up **Open WebUI** (Python 3.11) and **Ollama** on Google Colab. Both can optionally be installed in Google Drive to persist across sessions. **ngrok** is used to provide a public URL for the Open WebUI interface (port 8081). Ollama runs in the background on port 11422.\n",
        "\n",
        "### **Features**\n",
        "1. **Install** Open WebUI in a Python 3.11 virtual environment.\n",
        "2. **Optionally** persist Open WebUI and Ollama in Google Drive.\n",
        "3. **Expose** Open WebUI via ngrok.\n",
        "4. **Hide** Ollama from the public URL (internal only)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup_form"
      },
      "source": [
        "#@title **Setup**\n",
        "use_gdrive = True #@param {type:\"boolean\"}\n",
        "use_ngrok_auth = False #@param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "\n",
        "BASE_PATH = \"/content\"\n",
        "if use_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_PATH = \"/content/drive/MyDrive/Open-WebUI\"\n",
        "    os.makedirs(BASE_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Using base path:\", BASE_PATH)\n",
        "print(\"Using ngrok auth token:\", use_ngrok_auth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_sFOfTTQBfq"
      },
      "source": [
        "## (Optional) Using Authentication Token\n",
        "If you want a stable subdomain or advanced ngrok features, toggle `use_ngrok_auth` and provide your token in one of the following ways:\n",
        "- **Environment variable**: `%env ngrok_auth_token=YOUR_TOKEN`  \n",
        "- **Colab secrets**: Go to **Runtime** > **RunTime manager** > **Secrets** > add `ngrok_auth_token`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7S3tmLbQBfr"
      },
      "source": [
        "## Install Dependencies\n",
        "Installs Python 3.11, venv, development packages, and system tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_deps"
      },
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y python3.11 python3.11-venv python3.11-dev pciutils lshw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDbwGzAtQBfr"
      },
      "source": [
        "## Install Ollama\n",
        "If `use_gdrive` is **True**, Ollama is stored in Drive; otherwise it is installed system-wide."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_ollama"
      },
      "source": [
        "if use_gdrive:\n",
        "    print(\"Persisting Ollama to Drive...\")\n",
        "    import os\n",
        "    ollama_dir = os.path.join(BASE_PATH, 'ollama')\n",
        "    ollama_bin = os.path.join(ollama_dir, 'ollama')\n",
        "\n",
        "    if os.path.exists(ollama_bin):\n",
        "        print(\"Ollama already exists in Drive.\")\n",
        "    else:\n",
        "        print(\"Downloading Ollama (Linux x86_64) to Drive...\")\n",
        "        os.makedirs(ollama_dir, exist_ok=True)\n",
        "        OLLAMA_VERSION = \"v0.0.16\"  # example pinned version\n",
        "        DOWNLOAD_URL = f\"https://github.com/jmorganca/ollama/releases/download/{OLLAMA_VERSION}/ollama-{OLLAMA_VERSION}-Linux-x86_64.tar.gz\"\n",
        "        !wget -q \"$DOWNLOAD_URL\" -O /tmp/ollama.tar.gz\n",
        "        !tar -xzf /tmp/ollama.tar.gz -C \"$ollama_dir\" --strip-components 1\n",
        "        !chmod +x \"$ollama_bin\"\n",
        "        print(\"Ollama persisted at:\", ollama_bin)\n",
        "else:\n",
        "    print(\"Installing Ollama system-wide (ephemeral)\")\n",
        "    !curl -fsSL https://ollama.com/install.sh | sh\n",
        "    print(\"Ollama installed for this session.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aimF5y-gQBfs"
      },
      "source": [
        "## Set Up Virtual Environment & Install Open WebUI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "open_webui_install"
      },
      "source": [
        "import os\n",
        "\n",
        "venv_path = os.path.join(BASE_PATH, \"venv\")\n",
        "if not os.path.exists(venv_path):\n",
        "    print(\"Creating Python 3.11 virtual environment...\")\n",
        "    !python3.11 -m venv \"$venv_path\"\n",
        "\n",
        "print(\"Upgrading pip...\")\n",
        "!\"$venv_path/bin/python\" -m pip install --upgrade pip\n",
        "\n",
        "print(\"Installing Open WebUI...\")\n",
        "!\"$venv_path/bin/pip\" install open-webui\n",
        "\n",
        "print(\"Open WebUI installation complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yERARWLtQBfs"
      },
      "source": [
        "## Create a Script to Start Both Servers\n",
        "Ollama runs on port **11422**. Open WebUI runs on port **8081**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "start_servers"
      },
      "source": [
        "import os\n",
        "\n",
        "server_script_path = os.path.join(BASE_PATH, 'start_servers.py')\n",
        "if use_gdrive:\n",
        "    ollama_bin = os.path.join(BASE_PATH, 'ollama', 'ollama')\n",
        "else:\n",
        "    ollama_bin = 'ollama'\n",
        "\n",
        "script_content = f'''\\\n",
        "import subprocess, threading, time\\n\\n\n",
        "OLLAMA_CMD = \"{ollama_bin}\"\\n\\n\n",
        "def start_ollama():\\n\",\n",
        "    subprocess.run([OLLAMA_CMD, 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\\n\\n\n",
        "def start_open_webui():\\n\",\n",
        "    subprocess.run(['./venv/bin/open-webui', 'serve', '--port', '8081'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\\n\\n\n",
        "threading.Thread(target=start_ollama).start()\\n\",\n",
        "time.sleep(5)\\n\",\n",
        "threading.Thread(target=start_open_webui).start()\\n\"\"\"\n",
        "\n",
        "with open(server_script_path, 'w') as f:\n",
        "    f.write(script_content)\n",
        "\n",
        "print(\"Created:\", server_script_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ss_DKWQBft"
      },
      "source": [
        "## Start Servers & Expose Open WebUI via ngrok\n",
        "After a brief wait, the Open WebUI URL will be displayed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_ngrok"
      },
      "source": [
        "!pip install pyngrok --quiet\n",
        "\n",
        "import time, os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Attempt to retrieve ngrok token from environment or secrets\n",
        "def get_ngrok_token():\n",
        "    token_env = os.environ.get('ngrok_auth_token', '')\n",
        "    if token_env:\n",
        "        return token_env\n",
        "    # If colab secrets usage is desired, user might do something like:\n",
        "    # from google.colab import runtime\n",
        "    # secrets = runtime.authorized_users.secrets.get('ngrok_auth_token','')\n",
        "    # This can vary with different Colab setups. Provide your own logic if needed.\n",
        "    return ''\n",
        "\n",
        "if use_ngrok_auth:\n",
        "    token = get_ngrok_token()\n",
        "    if token:\n",
        "        ngrok.set_auth_token(token)\n",
        "        print(\"ngrok auth token set.\")\n",
        "    else:\n",
        "        print(\"No 'ngrok_auth_token' found. Proceeding without auth token.\")\n",
        "\n",
        "print(\"Starting servers...\")\n",
        "venv_path = os.path.join(BASE_PATH, 'venv')\n",
        "server_script_path = os.path.join(BASE_PATH, 'start_servers.py')\n",
        "!\"$venv_path/bin/python\" \"$server_script_path\" &\n",
        "time.sleep(20)\n",
        "\n",
        "webui_tunnel = ngrok.connect(8081, \"http\")\n",
        "print(\"Open WebUI URL:\", webui_tunnel.public_url)\n",
        "\n",
        "# Hidden tunnel for Ollama\n",
        "ollama_tunnel = ngrok.connect(11422, \"http\")\n",
        "\n",
        "print(\"\\nSetup complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}