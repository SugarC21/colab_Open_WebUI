{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SugarC21/colab_Open_WebUI/blob/main/Colab_Open_WebUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_GbOLQy1WHg"
      },
      "source": [
        "# Start Open WebUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAJf1k111XD6"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "name = \"\" # @param {\"type\":\"string\"}\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "\n",
        "if name == \"\":\n",
        "  webui_path = \"/content/drive/MyDrive/udocker_exports/open_webui_container.tar\";\n",
        "  ollama_path = \"/content/drive/MyDrive/udocker_exports/ollama_container.tar\";\n",
        "else:\n",
        "  webui_path = \"/content/drive/MyDrive/udocker_exports/open_webui_container_\" + name + \".tar\";\n",
        "  ollama_path = \"/content/drive/MyDrive/udocker_exports/ollama_container_\" + name + \".tar\";\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "# Install udocker if not installed\n",
        "!apt-get update\n",
        "!pip install udocker\n",
        "!udocker --allow-root install\n",
        "\n",
        "# Import necessary modules\n",
        "import os\n",
        "\n",
        "# Ensure export directory exists\n",
        "os.makedirs(\"/content/drive/MyDrive/udocker_exports\", exist_ok=True)\n",
        "!mkdir -p /content/drive/MyDrive/udocker_exports/ollama_models\n",
        "\n",
        "# Import containers if they exist, otherwise pull and create new ones\n",
        "if os.path.exists(ollama_path) and os.path.exists(webui_path):\n",
        "    print(\"Importing existing containers from Google Drive...\")\n",
        "    subprocess.run([\"udocker\", \"--allow-root\", \"load\", \"-i\", ollama_path, \"ollama_container\"])\n",
        "    subprocess.run([\"udocker\", \"--allow-root\", \"load\", \"-i\", webui_path, \"open_webui_container\"])\n",
        "    !udocker --allow-root create --name=open_webui_container open_webui_container:main\n",
        "    !udocker --allow-root create --name=ollama_container ollama_container:latest\n",
        "else:\n",
        "    print(\"No saved containers found. Pulling images and creating containers...\")\n",
        "    subprocess.run([\"udocker\", \"--allow-root\", \"pull\", \"ollama/ollama\"])\n",
        "    subprocess.run([\"udocker\", \"--allow-root\", \"pull\", \"ghcr.io/open-webui/open-webui:main\"])\n",
        "\n",
        "    subprocess.run([\"udocker\", \"--allow-root\", \"create\", \"--name=ollama_container\", \"ollama/ollama\"])\n",
        "    subprocess.run([\"udocker\", \"--allow-root\", \"create\", \"--name=open_webui_container\", \"ghcr.io/open-webui/open-webui:main\"])\n",
        "\n",
        "    # Export containers for future use\n",
        "    print(\"Saving containers to Google Drive for future sessions...\")\n",
        "    subprocess.run([\"udocker\", \"--allow-root\", \"save\", \"-o\", \"/content/drive/MyDrive/udocker_exports/ollama_container\", \"ollama_container\"])\n",
        "    subprocess.run([\"udocker\", \"--allow-root\", \"save\", \"-o\", \"/content/drive/MyDrive/udocker_exports/open_webui_container\", \"open_webui_container\"])\n",
        "\n",
        "!udocker --allow-root ps\n",
        "\n",
        "# Set execution mode\n",
        "#subprocess.run([\"udocker\", \"--allow-root\", \"setup\", \"--execmode=P1\", \"ollama_container\"])\n",
        "#subprocess.run([\"udocker\", \"--allow-root\", \"setup\", \"--execmode=P1\", \"open_webui_container\"])\n",
        "!udocker --allow-root setup --nvidia  ollama_container\n",
        "!udocker --allow-root setup --nvidia  open_webui_container\n",
        "\n",
        "# Start the containers as subprocesses and redirect logs to files\n",
        "\n",
        "# Define log file paths\n",
        "import time\n",
        "\n",
        "OLLAMA_LOG = \"/content/ollama.log\"\n",
        "WEBUI_LOG = \"/content/webui.log\"\n",
        "NGROK_LOG = \"/content/ngrok.log\"\n",
        "\n",
        "def stream_logs(log_file):\n",
        "    with open(log_file, \"r\") as f:\n",
        "        f.seek(0, os.SEEK_END)  # Move to the end of the file\n",
        "        while True:\n",
        "            line = f.readline()\n",
        "            if line:\n",
        "                print(f\"{log_file}: {line}\", end=\"\")\n",
        "            time.sleep(0.1)\n",
        "\n",
        "\n",
        "#!udocker --allow-root run --env=WEBUI_AUTH=False --publish=3000:8080 open_webui_container\n",
        "\n",
        "# Starting Ollama container with volume mapping for models\n",
        "print(\"Starting Ollama container...\")\n",
        "ollama_process = subprocess.Popen(\n",
        "    [\n",
        "        \"udocker\", \"--allow-root\", \"run\",\n",
        "        \"--env=OLLAMA_NOPRUNE=true\",\n",
        "        \"--publish=11434:11434\",\n",
        "        \"--volume=/content/drive/MyDrive/udocker_exports/ollama_models:/root/.ollama\",\n",
        "        \"ollama_container\"\n",
        "    ],\n",
        "    stdout=open(OLLAMA_LOG, \"w\"),\n",
        "    stderr=subprocess.STDOUT\n",
        ")\n",
        "\n",
        "print(\"Starting Open-WebUI container...\")\n",
        "webui_process = subprocess.Popen(\n",
        "    [\n",
        "        \"udocker\", \"--allow-root\", \"run\",\n",
        "        \"--env=OLLAMA_BASE_URL=http://0.0.0.0:11434\",\n",
        "        \"--env=WEBUI_AUTH=False\",\n",
        "        \"--publish=3000:8080\",\n",
        "        \"open_webui_container\"\n",
        "    ],\n",
        "    stdout=open(WEBUI_LOG, \"w\"),\n",
        "    stderr=subprocess.STDOUT\n",
        ")\n",
        "\n",
        "# Check running containers\n",
        "subprocess.run([\"udocker\", \"--allow-root\", \"ps\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_QhuSNcNkyG"
      },
      "outputs": [],
      "source": [
        "# !udocker --allow-root images -l\n",
        "# !udocker --allow-root rm 981b744d-b398-3e44-a7bc-6c1cb79d9732\n",
        "\n",
        "# !curl -v http://0.0.0.0:11434\n",
        "\n",
        "#webui_process.kill()\n",
        "\n",
        "!udocker --allow-root inspect -p open_webui_container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8Szc8Uj2f6x"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "# Set your ngrok auth token here\n",
        "from google.colab import userdata\n",
        "ngrok_auth_token = userdata.get('ngrok_auth_token')\n",
        "ngrok_auth_token = ngrok_auth_token\n",
        "\n",
        "# Initialize ngrok with auth token\n",
        "ngrok_process = subprocess.Popen(\n",
        "    [\n",
        "        'ngrok', 'http', '3000',\n",
        "        '--authtoken', ngrok_auth_token,\n",
        "        '--log', 'stdout'  # Direct logs to standard output\n",
        "    ], stdout=open(NGROK_LOG, \"w\"), stderr=subprocess.STDOUT\n",
        ")\n",
        "\n",
        "\n",
        "# Wait for tunnels to establish\n",
        "time.sleep(30)\n",
        "\n",
        "# Get public URL using ngrok API\n",
        "try:\n",
        "    tunnels = subprocess.check_output(['curl', '-s', 'http://localhost:4040/api/tunnels'])\n",
        "    public_url = str(tunnels).split('public_url\":\"')[1].split('\"')[0]\n",
        "    print(f\"\\nOpen WebUI Public URL: {public_url.replace('http://', 'https://')}\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"Error getting ngrok URL: {str(e)}\")\n",
        "\n",
        "\n",
        "import threading\n",
        "\n",
        "#threading.Thread(target=stream_logs, args=(OLLAMA_LOG,), daemon=True).start()\n",
        "#threading.Thread(target=stream_logs, args=(WEBUI_LOG,), daemon=True).start()\n",
        "##threading.Thread(target=stream_logs, args=(NGROK_LOG,), daemon=True).start()\n",
        "\n",
        "# Show running containers\n",
        "!udocker --allow-root ps\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TvJM54vKW-2",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Default title text\n",
        "save_changes = False # @param {\"type\":\"boolean\"}\n",
        "name = \"deepseek_70b\" # @param {\"type\":\"string\"}\n",
        "\n",
        "if save_changes != True:\n",
        "  print(\"here\")\n",
        "  raise SystemExit(\"Changes not saved!\")\n",
        "\n",
        "# Export ollama container\n",
        "ollama_container_name = \"/content/drive/MyDrive/udocker_exports/ollama_container_\" + name + \".tar\"\n",
        "!udocker --allow-root save -o $ollama_container_name ollama_container\n",
        "\n",
        "# Export open-webui container!\n",
        "open_webui_container_name = \"/content/drive/MyDrive/udocker_exports/open_webui_container_\" + name + \".tar\"\n",
        "!udocker --allow-root save -o $open_webui_container_name open_webui_container:main\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSHOURA1MAhp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vke0O2SC0ogE"
      },
      "source": [
        "# Create docker containers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF_T9N5glXPc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHt7bbbrlZG9"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!pip install udocker\n",
        "!udocker --allow-root install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEpZVPUDlbTJ"
      },
      "outputs": [],
      "source": [
        "# Pull necessary container images\n",
        "!udocker --allow-root pull ollama/ollama\n",
        "!udocker --allow-root pull ghcr.io/open-webui/open-webui:main\n",
        "\n",
        "# Create containers from the images\n",
        "!udocker --allow-root create --name=ollama_container ollama/ollama\n",
        "!udocker --allow-root create --name=open_webui_container ghcr.io/open-webui/open-webui:main\n",
        "\n",
        "# Set up execution mode (P1 for best compatibility)\n",
        "#!udocker --allow-root setup --execmode=P1 ollama_container\n",
        "#!udocker --allow-root setup --execmode=P1 open_webui_container$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnQc66vMxj2x"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/drive/MyDrive/udocker_exports  # Ensure export directory exists\n",
        "\n",
        "!udocker --allow-root images -l\n",
        "# Export ollama container\n",
        "!udocker --allow-root save -o /content/drive/MyDrive/udocker_exports/ollama_container.tar ollama/ollama:latest\n",
        "\n",
        "# Export open-webui container\n",
        "!udocker --allow-root save -o /content/drive/MyDrive/udocker_exports/open_webui_container.tar ghcr.io/open-webui/open-webui:main\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNQT+b6x0Veyi99EXxlKVC8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}